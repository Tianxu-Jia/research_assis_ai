# Title: One-to-Many Transfer Learning in Low-Dimensional Diffusion Models
# Experiment description: 1. Modify the training loop to save the model trained on the 'circle' dataset. 2. Implement a function to evaluate this trained model on all datasets using both KL divergence and evaluation loss. 3. Generate and visually compare samples from the transfer scenarios. 4. Repeat the experiment with different embedding dimensions (64, 128, 256) to analyze its impact on transfer performance. 5. Discuss implications for designing robust low-dimensional diffusion models.
## Run 0: Baseline
Results: {'circle': {'training_time': 22.78913640975952, 'eval_loss': 0.4352689213155176, 'inference_time': 0.16325092315673828, 'kl_divergence': 0.3390841615593227}, 'dino': {'training_time': 21.349066257476807, 'eval_loss': 0.6604227140126631, 'inference_time': 0.15765833854675293, 'kl_divergence': 1.0292828033411612}, 'line': {'training_time': 20.768935203552246, 'eval_loss': 0.8046935080262401, 'inference_time': 0.15740132331848145, 'kl_divergence': 0.1572009839576215}, 'moons': {'training_time': 20.56239104270935, 'eval_loss': 0.614176513593825, 'inference_time': 0.12911629676818848, 'kl_divergence': 0.09562104554894295}}
Description: Baseline results.
