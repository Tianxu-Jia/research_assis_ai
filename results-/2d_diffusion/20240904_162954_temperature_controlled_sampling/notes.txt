# Title: Temperature-Controlled Sampling in Low-Dimensional Diffusion Models: Balancing Quality and Diversity
# Experiment description: 1. Modify NoiseScheduler's step function to include a temperature parameter that scales the noise added during sampling. 2. Implement a temperature-controlled sampling function. 3. Train models on each dataset using the original settings. 4. Generate samples at various temperatures (0.5, 0.8, 1.0, 1.2, 1.5) for each trained model. 5. Evaluate samples using KL divergence, visual inspection, average pairwise distance (diversity metric), and a new mode coverage metric (e.g., k-means clustering). 6. Compare results at different temperatures with the baseline (temp=1.0). 7. Analyze the quality-diversity trade-off and mode coverage across different datasets and temperatures.
## Run 0: Baseline
Results: {'circle': {'training_time': 22.78913640975952, 'eval_loss': 0.4352689213155176, 'inference_time': 0.16325092315673828, 'kl_divergence': 0.3390841615593227}, 'dino': {'training_time': 21.349066257476807, 'eval_loss': 0.6604227140126631, 'inference_time': 0.15765833854675293, 'kl_divergence': 1.0292828033411612}, 'line': {'training_time': 20.768935203552246, 'eval_loss': 0.8046935080262401, 'inference_time': 0.15740132331848145, 'kl_divergence': 0.1572009839576215}, 'moons': {'training_time': 20.56239104270935, 'eval_loss': 0.614176513593825, 'inference_time': 0.12911629676818848, 'kl_divergence': 0.09562104554894295}}
Description: Baseline results.
